{"trial_id": "0000", "hyperparameters": {"space": [{"class_name": "Int", "config": {"name": "units", "default": null, "conditions": [], "min_value": 64, "max_value": 512, "step": 32, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "learning_rate", "default": 0.01, "conditions": [], "values": [0.01, 0.001], "ordered": true}}], "values": {"units": 384, "learning_rate": 0.001, "tuner/epochs": 2, "tuner/initial_epoch": 0, "tuner/bracket": 1, "tuner/round": 0}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\tuners\\hyperband.py\", line 425, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 52, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"E:\\Computer-Vision-Project\\Program\\Classification.py\", line 123, in <module>\n      tuner.search(train_dataset,\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 230, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\tuners\\hyperband.py\", line 425, in run_trial\n      return super().run_trial(trial, *fit_args, **fit_kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n      return model.fit(*args, **kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer.py\", line 542, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer.py\", line 275, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[1,16384,131072] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradient_tape/sequential/conv2d_1/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1697]\n"}